---
title: "Poll averages for the 2022 Australian election"
author: "Professor Simon Jackman"
date: "`r format(Sys.time(), '%e %B %Y')`"
site: workflowr::wflow_site
output:
  bookdown::html_document2:
    css: preamble.css
    toc: yes
    toc_float: yes  
    self-contained: true
fontsize: 11pt
link-citations: no
affiliation: University of Sydney
bibliography: [poll_averaging.bib]
editor_options:
  markdown:
    wrap: 80
---

```{r setup, include=FALSE}
library(knitr)
knitr::opts_chunk$set(echo = FALSE,
                      warnings = FALSE,
                      message = FALSE)
options(knitr.kable.NA = '')
options(htmltools.dir.version = FALSE)

library(tidyverse)
library(here)
library(fst)
library(r2d3)
options(r2d3.shadow = FALSE)
library(DT)
theStates <- c("ACT", "NT", "QLD", "NSW", "VIC", "TAS", "SA", "WA")

electionDates <- c(
  "1996" = as.Date("1996/03/02"),
  "1998" = as.Date("1998/10/03"),
  "2001" = as.Date("2001/11/10"),
  "2004" = as.Date("2004/10/09"),
  "2007" = as.Date("2007/11/24"),
  "2010" = as.Date("2010/08/21"),
  "2013" = as.Date("2013/09/07"),
  "2016" = as.Date("2016/07/02"),
  "2019" = as.Date("2019/05/18"),
  "2022" = as.Date("2022/05/21")
)

actual <-
  read_csv(file = here("data/historic/election_results.csv")) %>%
  mutate(date = as.Date(date, format = "%d/%m/%y")) %>%
  mutate(year = strftime(date, format = "%y")) %>%
  filter(date == max(date)) %>%
  rename(LNP_2PP = LNP2PP, ALP_2PP = ALP2PP) %>%
  pivot_longer(
    cols = c("LNP", "ALP", "GRN", "OTH", "LNP_2PP", "ALP_2PP"),
    names_to = "what",
    values_to = "y"
  )

actuals_2022 <- 
  tribble(
    ~what, ~y,
    "LNP", 35.69,
    "ALP", 32.58,
    "GRN", 12.25,
    "LNP_2PP", 47.87
  ) %>% 
  mutate(year = 2022)
```

# Summary

::: {#summary .highlights .nonumber}
-   This document was originally being updated regularly over the course of the 2022 election campaign; with actual result now in hand, this document serves as an archive of sorts, a basis for examining the performance of the polls and poll averages (to be presented elsewhere).   With just one or two exceptions highlighted in red, this document is as it was Election Day 21 May 2022.

-   Averages of recent polls indicate the Coalition will win 46.5% of the
    two-party preferred (TPP) vote; see Table \@ref(tab:load-summary-table).

-   The Coalition's estimated first preference vote of 35.8% is 5.6 percentage
    points down on 2019; Labor's first preference share is estimated at 35.8%, up
    2.5 points from 2019 and the Greens are estimated to have 12.0% of first
    preferences, up 1.6 points from 2019.

-   But if public, national polls are carrying the error they exhibited in 2019,
    the election is closer to 50.8-49.2 ALP/Coalition (TPP).

-   If the polls are carrying the average level of bias seen in the five
    previous elections (2007 to 2019), then the election is more likely 52.1% ALP TPP to the Coalition's 47.9%. 
    
-  <span style="color: #dd0000;">UPDATE (post-election): these average-bias-adjusted TPP results match the _actual_ election TPP results.</span>

-   It is extremely unlikely that the Coalition can form government if it were
    to win 47% or less of the national TPP vote.

-   The Coalition *did* form government in 1998 with 49% of the national TPP.
:::

At the end of the campaign:

```{r load-summary-table,eval=file.exists("/tmp/tab.RData")}
load("/tmp/tab.RData")
tab <- bind_rows(
  tab,
  
  actual %>%
    pivot_wider(
      id_cols = date,
      names_from = what,
      values_from = y
    ) %>%
    mutate(adjust = "2019 results") %>%
    select(-date, -OTH, -ALP_2PP),
  
  actuals_2022 %>% 
     pivot_wider(
      id_cols = year,
      names_from = what,
      values_from = y
    ) %>%
    mutate(adjust = "2022 results") %>%
    select(-year)
)

names(tab)[1] <- ""

kable(
  tab,
  caption = ##paste(
    "Summary of poll averages and adjustments"
  ##, computed",
  ##  format(min(c(
  ##    Sys.time(), electionDates["2022"]
  ##  )), '%e %B %Y')
  ##)
  ,
  digits = 1,
  format = "html"
) %>%
  ##kableExtra::row_spec(1:2, hline_after = TRUE) %>%
  kableExtra::row_spec(4:5,hline_after = TRUE) %>% 
  kableExtra::row_spec(6,color = "#dd0000") %>% 
  kableExtra::kable_styling(full_width = TRUE,
                            bootstrap_options = "basic")
```

# Errors in poll averages, Australian elections 2007 to 2019

Averages of opinion polls figure prominently in commentary and prognostication
about the upcoming Federal election. My work is being used by the ABC regularly,
including on its flagship *Insiders* programme.

By and large, 2019 pre-election polls --- and averages of those polls --- missed
the mark. After vigorous introspection, and the formation of an Australian
Polling Council, some polling firms have changed their methodology and methods
of reporting. Polls fielded shortly before recent state elections were
reasonably accurate, bolstering confidence that 2022 election polls will be more
accurate than in 2019.

We draw on analysis presented in summary form in
@mansilloNationalPollingOther2020, where a poll-averaging model was fit to
Australian opinion polls fielded in the period 2007-2019.

Details on the poll averaging model and fitting it to published polling data
appear in the Appendix.

Figure \@ref(fig:load-older-runs) shows the performance of poll averages in five
previous elections: 2007, 2010, 2013, 2016 and 2019, graphing the error of the
poll average computed over time until the election. Error is defined as poll
average minus the actual election result, so that

-   positive errors mean the polls are *over-estimates* of a party's actual
    level of support, or that the polls are collectively *biased upwards* with
    respect to that party

-   conversely, negative errors mean the polls are *under-estimates* of a
    party's actual level of support, or that the polls are collectively *biased
    downwards* with respect to that party

Since the poll average can be updated daily (even if the absence of new polls),
we compute and plot errors in the poll average as daily time series in Figure
\@ref(fig:load-older-runs). 2019 poll error is highlighted in orange, while the
blue line displays the average of the poll errors on a particular day for each
party, averaging over the five elections (2007 to 2019, inclusive). The graph
zooms in on the sixty days prior to each election.

```{r load-older-runs,message=FALSE,warning=FALSE,fig.width=9,fig.cap="Errors in poll averages, by party, year and days until election, 2007, 2010, 2013, 2016 and 2019."}
getError <- function(y, p) {
  theFile <- here(paste0("output/", y, "/", p, "_", "summary.RData"))
  load(theFile)
  out <- forCasey %>%
    filter(type == "Poll average") %>%
    mutate(
      actual = thisElectionResult,
      error = xi - actual,
      days_to_election = -as.numeric(date - max(date)),
      year = as.character(y),
      party = p
    ) %>%
    select(xi, lo, up, actual, error, date, days_to_election, year, party)
  return(out)
}

error <- list()
counter <- 0
for(y in c(2019, 2016, 2013, 2010, 2007)) {
  for (p in c("ALP", "LNP", "GRN", "OTH", "LNP2PP")) {
    counter <- counter + 1
    error[[counter]] <- getError(y, p)
  }
}

library(mgcv)
library(modelr)
error <- bind_rows(error)
m <- error %>%
  group_by(party, days_to_election) %>%
  summarise(error = mean(error)) %>%
  ungroup() %>%
  mutate(year = "Average")

error <-
  bind_rows(error, m) %>% arrange(year, party, days_to_election)

write_csv(error, file = "/tmp/all_years.csv")

# error <- bind_rows(error,m) %>%
#   mutate(y2019 = factor(
#     case_when(year=="2019" ~ "2019",
#               year=="Average" ~ "Average",
#               TRUE ~ "Other"),
#     levels=c("2019","Other","Average")
#   )
#   ) %>%
#   arrange(party,year,days_to_election)

error <- error %>%
  mutate(y2019 = factor(
    case_when(year == "2019" ~ "2019",
              year == "Average" ~ "Average",
              TRUE ~ "Other"),
    levels = c("2019", "Average", "Other")
    )
    )

ggplot(
  error %>% filter(days_to_election < 60),
  aes(
    x = days_to_election,
    y = error,
    group = year,
    color = y2019
  )
) +
  geom_line(linewidth = 1.25) +
  geom_hline(yintercept = 0) +
  #geom_smooth(data=error %>%
  #              mutate(y2019="Average",
  #                     y2019=factor(y2019)),
  #            inherit.aes = FALSE,
  #            aes(x=days_to_election,y=error,color=y2019),
  #            se=FALSE,
  #            method=mgcv::gam,
  #            formula=y ~ s(x)) +
  scale_x_continuous(
    "Days until election",
    trans = "reverse",
    minor_breaks = NULL,
    breaks = c(0, 15, 30, 45, 60),
    limits = c(60, 0)
  ) +
  scale_y_continuous(
    "Forecast error of poll average",
    minor_breaks = NULL,
    breaks = seq(-4, 6, by = 2)
  ) +
  scale_color_manual("", values = c(
    "2019" = "orange",
    "Other" = gray(.70),
    "Average" = "blue"
  )) +
  facet_wrap( ~ party) +
  theme_minimal(base_family = "Avenir") +
  theme(legend.position = c(.875, .125))

```

<br>

First, the good news:

-   as the election gets closer, poll averages perform better, with errors
    getting smaller, with the possible exception of estimates of vote shares for
    the Greens.

-   by Election Day, the average error of the poll averages is generally small,
    ranging from 0.5 for the Labor Party's primary vote share to -1.3 for the
    Coalition's share of the two-party preferred vote; see Table
    \@ref(tab:error-final).

-   the party winning the two-party preferred vote almost always forms
    government: rare exceptions are 1998 and 1990. Between 2007 and 2019, poll
    averages of the two-party preferred result have picked the election winner
    correctly, save in 2019. In 2010 the polls under-estimated the Coalition's
    performance by a sizeable margin with a poll average of 48.1% versus the
    actual result of 49.9% and 73 of 150 seats.

<br>

```{r error-final}
actual <-
  read_csv(file = here::here("data/historic/election_results.csv")) %>%
  mutate(year = lubridate::year(as.Date(date, format = "%d/%m/%y"))) %>%
  filter(year > 2006) %>%
  mutate(year = as.character(year)) %>%
  select(year, actual = LNP2PP)

tab <- error %>%
  filter(days_to_election == 0) %>%
  pivot_wider(id_cols = year,
              names_from = party,
              values_from = error) %>%
  left_join(actual, by = "year") %>%
  select(year, ALP, LNP, GRN, OTH, LNP2PP, actual)

kable(
  tab %>%
    mutate(
      across(where(is.double),
             ~ str_squish(sprintf(.x, fmt = "%3.1f"))),
      actual = if_else(actual == "NA", "", actual)
    ),
  format = "html",
  align = "lrrrrrr",
  caption = "Election Day error of poll averages, 2007 to 2019 and average.  Positive/negative errors = polls are over/under estimates of party support."
) %>%
  kableExtra::kable_styling(bootstrap_options = "striped") %>%
  kableExtra::row_spec(row = 6, bold = TRUE)
                 
```

The less good news:

-   Australian polls exhibit biases that persist over decades. ALP and Green
    1st preferences are typically over-estimated, while Coalition and "Other"
    are usually under-estimated by averaging over public polls.

-   Unsurprisingly then, poll averages typically underestimate the Coalition's
    share of the two-party preferred vote, by an average of 1.1 percentage
    points.

-   The poll errors of 2019 are large both in absolute terms and relative to
    errors in other elections. The underestimate of the Coalition's first
    preference vote share, 3.6 percentage points, has a magnitude more than
    twice that seen in the four previous elections for either major party. The
    2.5 percentage point miss on the two-party preferred vote in 2019 was more
    than twice the average magnitude of the corresponding errors in the earlier elections.

<br>

# Poll averages for 2022: the story so far

What does this past history with respect to the errors in poll averages imply
for the poll averages constructed from the 2022 data?

We begin by presenting poll averages from the 2019-2022 election cycle, to date.

```{r}
getCurrentState <- function() {
  p <- c("ALP", "LNP", "GRN", "LNP_2PP")
  out <- list()
  for (theParty in p) {
    theFiles <- list.files(
      path = here("output"),
      pattern = paste("xi", theParty, sep = "_"),
      full.names = TRUE
    )
    if (!grepl(pattern = "_2PP", theParty)) {
      theFiles <- theFiles[!grepl(pattern = "_2PP", theFiles)]
    }
    
    theTimes <- file.mtime(theFiles)
    theFile <- theFiles[which.max(theTimes)]
    ##print(theFile)
    xi <- readRDS(theFile)
    ##print(xi)
    out[[theParty]] <- xi
  }
  
  out <- bind_rows(out, .id = "party")
  if(Sys.Date() > electionDates["2022"]){
    out <- out %>% 
      filter(date == max(date))
  } else {
    out <- out %>%
      filter(date == Sys.Date())
    }
  
  return(out)
}

tab <- getCurrentState() %>%
  select(party, mean, lo = `2.5%`, up = `97.5%`) %>%
  pivot_longer(
    cols = c("mean", "lo", "up"),
    names_to = "what",
    values_to = "x"
  ) %>%
  mutate(x = x * 100) %>%
  pivot_wider(id_cols = party,
              names_from = what,
              values_from = x) %>%
  mutate(mean = sprintf(mean, fmt = "%3.1f")) %>%
  mutate(ci = paste0(
    "[",
    sprintf(lo, fmt = "%3.1f"),
    " - ",
    sprintf(up, fmt = "%3.1f"),
    "]"
  )) %>%
  pivot_longer(
    cols = c("mean", "ci"),
    names_to = "what",
    values_to = "Estimate"
  ) %>%
  select(party, Estimate)

```

```{r load-and-plot,results='hide'}
source(here("R/process_poll_data.R"))

actual <-
  read_csv(file = here("data/historic/election_results.csv")) %>%
  mutate(date = as.Date(date, format = "%d/%m/%y")) %>%
  mutate(year = strftime(date, format = "%y")) %>%
  filter(date == max(date)) %>%
  rename(LNP_2PP = LNP2PP, ALP_2PP = ALP2PP) %>%
  pivot_longer(
    cols = c("LNP", "ALP", "GRN", "OTH", "LNP_2PP", "ALP_2PP"),
    names_to = "what",
    values_to = "y"
  )


get_xi <- function(theParty,
                   latest = TRUE,
                   theDate = NULL) {
  theFiles <- list.files(
    path = here("output"),
    pattern = paste("xi", theParty, sep = "_"),
    full.names = TRUE
  )
  if (!grepl(pattern = "_2PP", theParty)) {
    theFiles <- theFiles[!grepl(pattern = "_2PP", theFiles)]
  }
  
  theTimes <- file.mtime(theFiles)
  if (latest) {
    f <- theFiles[which.max(theTimes)]
  } else {
    f <- theFiles[grepl(pattern = theDate, theFiles)]
  }
  ##print(f)
  
  xi <- readRDS(f)
  return(xi)
}

inspect <-
  function(theParty,
           latest = TRUE,
           theDate = NULL,
           zoom = FALSE,
           overlay_2019 = FALSE) {
    xi <- get_xi(theParty, latest, theDate)
    
    colors <- tribble(
      ~ color, ~ Party,
      "#ed1b35", "ALP",
      "#009de3", "LNP",
      "darkgreen", "GRN",
      "#ee4627",
      "OTH",
      "#ed1b35",
      "ALP_2PP",
      "#009de3",
      "LNP_2PP"
    )
    
    thisCol <- colors %>% filter(Party == theParty) %>% pull(color)
    election_2019_result <-
      actual %>% filter(what == theParty) %>% pull(y)
    require(ggplot2)
    g <- ggplot(xi,
                aes(
                  x = date,
                  y = mean * 100,
                  ymin = `2.5%` * 100,
                  ymax = `97.5%` * 100
                ))
    
    
    g <- g +
      geom_ribbon(fill = gray(.85), alpha = .5) +
      geom_line(linewidth = 3, color = thisCol) +
      geom_linerange(
        data = d2022,
        inherit.aes = FALSE,
        color = gray(.75),
        size = .5,
        alpha = .5,
        aes(
          xmin = start_date_2,
          xmax = end_date_2,
          y = get(theParty)
        )
      ) +
      geom_point(data = d2022,
                 inherit.aes = FALSE,
                 aes(x = mid_date, y = get(theParty))) +
      geom_hline(yintercept = election_2019_result) +
      annotate(
        "text",
        x = min(xi$date),
        y = election_2019_result + .1,
        label = "2019 Result",
        family = "Avenir",
        vjust = 0,
        hjust = 0
      ) +
      annotate(
        "text",
        x = max(xi$date),
        y = election_2019_result + .1,
        label = "2019 Result",
        family = "Avenir",
        vjust = 0,
        hjust = 1
      ) +
      scale_y_continuous("Voting intention", minor_breaks = NULL)
    
    
    if (overlay_2019) {
      dateOffset <-
        difftime(as.Date(electionDates["2022"]), as.Date(electionDates["2019"]))
      theFile <-
        here(paste0("output/2019/xi_", theParty, "_sum_to_zero.rds"))
      if (grepl("2PP", theParty)) {
        theFile <-
          here(paste0(
            "output/2019/xi_",
            str_remove(theParty, pattern = "_"),
            "_sum_to_zero.rds"
          ))
      }
      xi_2019 <- read_rds(file = theFile) %>%
        mutate(date = date + dateOffset)
      
      g <- g +
        geom_line(data = xi_2019,
                  inherit.aes = FALSE,
                  aes(x = date, y = mean * 100)) +
        annotate(
          "text",
          x = max(xi_2019$date),
          y = xi_2019$mean[nrow(xi_2019)] * 100 + .1,
          label = "2019 Poll Average",
          family = "Avenir",
          vjust = 0,
          hjust = 1
        )
    }
    
    
    if (zoom) {
      library(ggrepel)
      g <- g +
        geom_text_repel(
          data = d2022,
          inherit.aes = FALSE,
          size = 3,
          aes(
            x = mid_date,
            y = get(theParty),
            label = pollster_abbr
          ),
          family = "Avenir"
        ) +
        scale_x_date(
          "",
          date_breaks = "1 month",
          expand = c(0, 0),
          date_labels = "%b %y",
          minor_breaks = NULL,
          limits = c(as.Date("2022-01-01"), as.Date("2022-05-21"))
        )
    } else {
      g <- g +
        scale_x_date(
          "",
          date_breaks = "3 months",
          expand = c(0, 0),
          date_labels = "%b %y",
          minor_breaks = NULL
        )
    }
    g <- g +
      theme_minimal(base_family = "Avenir")
    
    return(g)
  }

## CONSTANTS
electionDay_2019 <- as.Date("2019/05/18")
electionDay_2022 <- as.Date("2022/05/21")

## previous election results, we only need 2019 here
actual <-
  read_csv(file = here("data/historic/election_results.csv")) %>%
  mutate(date = as.Date(date, format = "%d/%m/%y")) %>%
  mutate(year = strftime(date, format = "%y")) %>%
  filter(date == max(date)) %>%
  rename(LNP_2PP = LNP2PP, ALP_2PP = ALP2PP) %>%
  pivot_longer(
    cols = c("LNP", "ALP", "GRN", "OTH", "LNP_2PP", "ALP_2PP"),
    names_to = "what",
    values_to = "y"
  )

## date Sequence
dateSeq <- seq.Date(from = electionDay_2019,
                    to = electionDay_2022,
                    by = 1)
```

```{r,alp-plot,fig.width=9,fig.height=6,purl=FALSE,fig.cap="ALP 1st preferences"}
inspect("ALP")
```

```{r lnp-plot,fig.width=9,fig.height=6.5,fig.cap="LNP 1st preferences",echo=FALSE}
inspect("LNP")
```

```{r grn-plot,fig.width=9,fig.height=6.5,fig.cap="GRN 1st preferences",echo=FALSE}
inspect("GRN")
```

```{r lnp-2pp-plot,fig.width=9,fig.height=6.5,fig.cap="LNP two party preferred",echo=FALSE}
inspect("LNP_2PP")
```

## 2022 zoom-in with 2019 overlay

We also zoom-in on calendar year 2022, overlaying the poll average from the same
stage of the 2019 campaign.

```{r alp-plot-zoom,fig.width=9,fig.height=6.5,fig.cap="ALP 1st preferences, 2022",echo=FALSE,message=FALSE,warning=FALSE}
inspect("ALP", zoom = TRUE, overlay_2019 = TRUE)
```

```{r lnp-plot-zoom,fig.width=9,fig.height=6.5,fig.cap="LNP 1st preferences, 2022",echo=FALSE,message=FALSE,warning=FALSE}
inspect("LNP", zoom = TRUE, overlay_2019 = TRUE)
```

```{r grn-plot-zoom,fig.width=9,fig.height=6.5,fig.cap="GRN 1st preferences, 2022",echo=FALSE,message=FALSE,warning=FALSE}
inspect("GRN", zoom = TRUE, overlay_2019 = TRUE)
```

```{r lnp-2pp-plot-zoom,fig.width=9,fig.height=6.5,fig.cap="LNP two party preferred, 2022",echo=FALSE,message=FALSE,warning=FALSE}
inspect("LNP_2PP", zoom = TRUE, overlay_2019 = TRUE)
```

# Adjusting 2022 poll averages given errors in past years

We consider three adjustments to the 2022 poll averages:

-   day-specific 2019 error.

-   day-specific average error, computed from poll averages 2007 to 2019,
    inclusive.

-   sampling from error distribution given errors listed in Table
    \@ref(tab:error-final), subject to the constraint that there is a 20% chance
    of errors larger than the largest errors observed in previous elections.

```{r,cache=TRUE}
error <- read_csv(file = "/tmp/all_years.csv") %>%
  mutate(party = if_else(party == "LNP2PP", "LNP_2PP", party))

t_obj <- function(parm, target) {
  df <- parm
  out <- abs(abs(target) - qt(.95, df = df))
  return(out)
}

get_t_distribution <- function(e) {
  m <- mean(e)
  s <- sd(e)
  e_star <- (e - m) / s
  k <- max(abs(e_star))
  
  df <- optimize(f = t_obj,
                 target = k,
                 interval = c(2, 30))$minimum
  return(list(m = m, s = s, df = df))
}

get_unif_errors <- function(obj) {
  if (any(is.na(obj))) {
    return(NULL)
  }
  e <- obj$error
  r <- max(e) - min(e)
  lo <- min(e) - .1 * r
  up <- max(e) + .1 * r
  error <- runif(n = 5000, lo, up)
  return(error)
}

make_t_sims <- function(e) {
  n <- length(e)
  if (n < 3) {
    return(NULL)
  }
  theta <- get_t_distribution(e)
  errors <- stats::rt(n = 5000, df = theta$df) * theta$s + theta$m
  return(errors)
}

perturb_xi <- function(xi) {
  out <- xi %>%
    left_join(
      error %>%
        select(error, days_to_election, party, year) %>%
        filter(year != "Average" & party %in% xi$party) %>%
        select(-party),
      by = c("days_to_election")
    )
  
  out <- out %>%
    group_nest(days_to_election, keep = TRUE) %>%
    mutate(error = map(.x = data,  ~ get_unif_errors(.x))) %>%
    ungroup() %>%
    unnest(error) %>%
    select(-data)
  
  out <- inner_join(xi, out, by = "days_to_election") %>%
    mutate(mean_adjust = mean - error) %>%
    group_by(days_to_election) %>%
    summarise(
      date = date[1],
      mean = mean[1],
      lo = lo[1],
      up = up[1],
      party = gsub(party, pattern = "_", replacement = "")[1],
      mean_adjust_lo = quantile(mean_adjust, .025),
      mean_adjust_up = quantile(mean_adjust, .975),
      mean_adjust = mean(mean_adjust)
    ) %>%
    ungroup()
  
  return(out)
}

adjust <-
  function(theParty,
           adjust = c("average", "2019_end", "sampling")) {
    xi <- get_xi(theParty, latest = TRUE, theDate = NULL) %>%
      select(-n_eff, -Rhat) %>%
      rename(lo = `2.5%`, up = `97.5%`) %>%
      mutate(across(where(function(x)
        is.double(x) & !is.Date(x)),  ~ .x * 100)) %>%
      mutate(days_to_election = as.numeric(base::difftime(
        as.Date("2022-05-21"),
        as.Date(date),
        units = "day"
      ))) %>%
      mutate(party = theParty)
    
    if (adjust == "average") {
      xi <- left_join(
        xi,
        error %>%
          filter(year == "Average") %>%
          select(party, error, days_to_election),
        by = c("party", "days_to_election")
      ) %>%
        mutate(
          mean_adjust = mean - error,
          mean_adjust_lo = lo - error,
          mean_adjust_up = up - error
        )
      
    }
    
    if (adjust == "2019_end") {
      xi <- left_join(
        xi,
        error %>%
          filter(year == "2019") %>%
          select(party, error, days_to_election),
        by = c("party", "days_to_election")
      ) %>%
        mutate(
          mean_adjust = mean - error,
          mean_adjust_lo = lo - error,
          mean_adjust_up = up - error
        )
    }
    
    if (adjust == "sampling") {
      xi <- perturb_xi(xi)
    }
    
    out <- xi %>% mutate(adjust = adjust)
    
    out <- bind_rows(
      out %>%
        rename(mean_lo = lo, mean_up = up) %>%
        select(date, days_to_election, party,
               mean, mean_lo, mean_up, adjust) %>%
        mutate(type = 'raw'),
      out %>%
        select(date, days_to_election, party,
               contains("_adjust"),
               adjust) %>%
        rename(
          mean = mean_adjust,
          mean_lo = mean_adjust_lo,
          mean_up = mean_adjust_up
        )  %>%
        mutate(type = 'adjusted')
    )
    
    return(out)
  }

xi_adjust <- list()
counter <- 0
for (p in c("ALP", "LNP", "GRN", "LNP_2PP")) {
  for (adj in c("average", "2019_end", "sampling")) {
    ##cat(paste(p,adj,"\n"))
    counter <- counter + 1
    xi_adjust[[counter]] <- adjust(p, adj)
  }
}

xi_adjust <- bind_rows(xi_adjust) %>%
  mutate(party = if_else(party == "LNP2PP", "LNP_2PP", party)) %>%
  mutate(adjust = factor(
    adjust,
    levels = c("2019_end", "average", "sampling"),
    labels = c(
      "Correct for 2019 error",
      "Correct for average error",
      "Integrating uncertainty\nin average & error"
    )
  ))
```

```{r show-adjust}
show_adjust <- function(theParty) {
  colors <- tribble(
    ~ color, ~ Party,
    "#ed1b35", "ALP",
    "#009de3", "LNP",
    "darkgreen", "GRN",
    "#ee4627", "OTH",
    "#ed1b35", "ALP_2PP",
    "#009de3", "LNP_2PP"
  )
  
  theColor <- colors %>% filter(Party == theParty) %>% pull(color)
  ##print(theParty)
  ##print(theColor)
  
  g <- ggplot(
    data = xi_adjust %>%
      filter(days_to_election < 46) %>%
      filter(party == theParty),
    aes(
      x = days_to_election,
      y = mean,
      ymin = mean_lo,
      ymax = mean_up,
      group = type,
      fill = type,
      color = type
    )
  ) +
    geom_ribbon(alpha = .35,
                show.legend = FALSE,
                color = "transparent") +
    geom_line(size = 1.25, show.legend = TRUE) +
    scale_fill_manual(
      "",
      values = c("raw" = gray(.5),
                 "adjusted" = theColor),
      aesthetics = c("fill", "color")
    ) +
    scale_x_reverse("Days to election", minor_breaks = NULL) +
    scale_y_continuous("", minor_breaks = NULL) +
    facet_grid(cols = vars(adjust)) +
    theme_minimal(base_family = "Avenir") +
    theme(
      legend.position = "top",
      legend.direction = "horizontal",
      legend.margin = margin(0, 0, 0, 0)
    )
  
  return(g)
}
```

```{r adjust-alp,fig.cap="Adjusted poll average, ALP 1st preferences",fig.height=3.5}
show_adjust("ALP")
```

```{r adjust-lnp,fig.cap="Adjusted poll average, Coalition 1st preferences",fig.height=3.5}
show_adjust("LNP")
```

```{r adjust-grn,fig.cap="Adjusted poll average, Green 1st preferences",fig.height=3.5}
show_adjust("GRN")
```

```{r adjust-lnp-2pp,fig.cap="Adjusted poll average, LNP two-party preferred",fig.height=3.5}
show_adjust("LNP_2PP")
```

```{r summary-adjust-tab}
tab <- bind_rows(
  xi_adjust %>%
    filter(days_to_election == 0 & type == "raw") %>%
    select(-adjust) %>%
    distinct() %>%
    mutate(adjust = "Unadjusted poll average") %>%
    pivot_wider(
      id_cols = adjust,
      names_from = party,
      values_from = mean
    ),
  xi_adjust %>%
    filter(days_to_election == 0 & type == "adjusted") %>%
    pivot_wider(
      id_cols = adjust,
      names_from = party,
      values_from = mean
    ) %>%
    slice(c(2, 1, 3))
)

save("tab", file = "/tmp/tab.RData")
```

# Appendix

## Poll average model

Each poll $p \in 1, \ldots, P$ is fielded on day $t(p)$ by polling firm
("house") $j(p)$.

Each poll for each party (not indexed here for clarity) yields a proportion
$y_p$ and a sample size $n_p$.

Polls are modelled as $y_p \sim N(\mu_p, s_p^2)$:

-   $\mu_p = \xi_{t(p)} + \delta_{j(p)}$,

-   $\xi_t$ the underlying level of support for the party in question on day
    $t$.

-   $\delta_j$ is a bias term ("house effect") for polling firm $j$.

-   $s_p^2 = y_p (1 - y_p)/n_p$ is an approximation to the sampling variability
    of $y_p$.

Underlying levels of support evolve according to a "locally constant" or
Gaussian random walk, $\xi_t \sim N(\xi_{t-1}, \omega^2)$ where

-   $\omega^2$ is the variance of day-to-day innovations in underlying voting
    intentions

-   $\xi_1$ is observed, the level of support for the political party in
    question on day $t=1$, the day of the last election.

In summary:

-   Observed: $y_p, n_p, \xi_1$.

-   Unknowns: $\xi_2, \ldots, \xi_T, \omega^2, \delta_j$.

We impose the normalising assumption $\sum_j \delta_j = 0$, an assumption that
the polls are collectively unbiased.

We approach estimation and inference for the unknown model parameters in a
Bayesian setting, using Markov chain Monte Carlo methods to explore the
posterior density of the parameters given observables and the model structure.

See @jackmanBayesianAnalysisSocial2009 and @jackman2005 for additional details.

`R` and `stan` code appears in the [github
archive](https://github.com/simonjackman/poll_averaging_aus_2022)
for this project.

## Data

Poll data for 2022 used for this project is listed below.   The file [`R/process_poll_data.R`](https://github.com/simonjackman/poll_averaging_aus_2022/blob/main/R/process_poll_data.R) contains code for preparing published poll results for incorporation into the poll-average model and analysis, with adjustments for allocation of undecided percentages, the translation to two-party preferred estimates, missing effective sample sizes and so on.

These data were collected by Casey Briggs and co-workers at the Australian Broadcasting Corporation.


```{r list-data}
datatable(d2022 %>% 
            mutate(Publisher = if_else(is.na(OriginalStory),
                                       Publisher,
                                       paste0("<a target=_blank href='",
                                              OriginalStory,
                                              "'>",
                                              Publisher,
                                              "</a>")
                                       )
                   ) %>%
            select(Pollster,Publisher,
                   start=start_date_2,end=end_date_2,
                   n_eff=EffectiveSampleSize,
                   ALP,LNP,GRN,LNP_2PP) %>%
            arrange(desc(end)),
          options=list(columnDefs=list(list(className = 'dt-left', targets=0:4))),
          rownames = FALSE,
          escape=FALSE,
          caption = "Poll data entering poll averaging model")  %>%
  formatRound(columns=c('ALP','LNP','GRN',"LNP_2PP"),1) %>%
  formatRound(columns="n_eff",0)
```


# References
